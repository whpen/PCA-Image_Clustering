{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model,Sequential,load_model\n",
    "from keras.layers import Dense, Embedding, Input,\\\n",
    "                                    Dropout,BatchNormalization, Activation,\\\n",
    "                                   Conv2D,Flatten,LeakyReLU,MaxPooling2D, Conv2DTranspose,Reshape,UpSampling2D,GaussianNoise\n",
    "from keras import optimizers\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_MAC= '/Users/haipengwu/Codings/Machine Learning/HW7/'\n",
    "DIR_1080=\"C:\\\\Users\\\\WIN10\\\\Codings\\\\Machine Learning\\\\HW7\\\\\"\n",
    "\n",
    "DIR = DIR_1080\n",
    "TRAIN_DIR= DIR+ \"images\\\\train\"\n",
    "VALIDATION_DIR = DIR+ \"images\\\\validation\"\n",
    "TEST_DIR = DIR+ \"images\\\\test\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image load and augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36000 images belonging to 1 classes.\n",
      "Found 4000 images belonging to 1 classes.\n",
      "Found 40000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 200\n",
    "IMG_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        samplewise_center=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.3,\n",
    "        rotation_range=0.3,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip = True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        target_size=(IMG_SIZE,IMG_SIZE),\n",
    "        batch_size = BATCH_SIZE,\n",
    "        shuffle= False,\n",
    "        class_mode = 'input')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        VALIDATION_DIR,\n",
    "        target_size=(IMG_SIZE,IMG_SIZE),\n",
    "        batch_size = BATCH_SIZE,\n",
    "        shuffle= False,\n",
    "        class_mode = 'input')\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=(IMG_SIZE,IMG_SIZE),\n",
    "        batch_size = BATCH_SIZE,\n",
    "        shuffle= False,\n",
    "        class_mode = 'input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1\\\\000001.jpg',\n",
       " '1\\\\000002.jpg',\n",
       " '1\\\\000003.jpg',\n",
       " '1\\\\000004.jpg',\n",
       " '1\\\\000005.jpg',\n",
       " '1\\\\000006.jpg',\n",
       " '1\\\\000007.jpg',\n",
       " '1\\\\000008.jpg',\n",
       " '1\\\\000009.jpg',\n",
       " '1\\\\000010.jpg']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.filenames[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 1000\n",
    "\n",
    "def auto_encoder():\n",
    "    \n",
    "    #Encoding\n",
    "    input_img = Input(shape = (IMG_SIZE,IMG_SIZE,3))\n",
    "#     encoded = GaussianNoise(0.1)\n",
    "    encoded = Conv2D(32,kernel_size=3,strides = 1,input_shape=(IMG_SIZE,IMG_SIZE,3),padding='SAME' )(input_img)\n",
    "    encoded =MaxPooling2D(pool_size=(2,2))(encoded)\n",
    "    encoded =BatchNormalization(momentum=.9)(encoded)\n",
    "    encoded =Activation('relu')(encoded)\n",
    "    \n",
    "    encoded = Conv2D(32,kernel_size=3,strides = 1,padding='SAME' )(encoded)\n",
    "    encoded = MaxPooling2D(pool_size=(2,2))(encoded)\n",
    "    encoded = BatchNormalization(momentum=.9)(encoded)\n",
    "    encoded = Activation('relu')(encoded)\n",
    "#     encoded = Dropout(0.5)(encoded)\n",
    "    \n",
    "    encoded = Flatten()(encoded)    \n",
    "\n",
    "    \n",
    "    ##Code layer to 'encoding_dim' dimensions\n",
    "    code_layer_output = Dense(encoding_dim,activation='tanh')(encoded)\n",
    "    \n",
    "    ##Decoding\n",
    "    \n",
    "    decoded = Dense(8*8*32,activation='relu')(code_layer_output)\n",
    "    \n",
    "    decoded=Reshape((8,8,32))(decoded)\n",
    "    \n",
    "    decoded=Conv2DTranspose(32,kernel_size=3,strides=1,padding=\"SAME\")(decoded)\n",
    "    decoded=UpSampling2D(size=(2,2))(decoded)\n",
    "    decoded=BatchNormalization(momentum=.9)(decoded)\n",
    "    decoded=Activation('relu')(decoded)\n",
    "    \n",
    "    decoded=Conv2DTranspose(32,kernel_size=3,strides=1,padding=\"SAME\")(decoded)\n",
    "    decoded=UpSampling2D(size=(2,2))(decoded)\n",
    "    decoded=BatchNormalization(momentum=.9)(decoded)\n",
    "    decoded=Activation('relu')(decoded)  \n",
    "    \n",
    "    decoded=Conv2DTranspose(3,kernel_size=3,strides=1,padding=\"SAME\")(decoded)\n",
    "    decoded_output = Activation('sigmoid')(decoded)\n",
    "    \n",
    "    \n",
    "\n",
    "           \n",
    "    auto_encoder = Model(inputs = input_img, outputs = decoded_output)\n",
    "    auto_encoder.summary()\n",
    "    \n",
    "    \n",
    "\n",
    "    code_layer =Model(inputs = input_img, outputs = code_layer_output)\n",
    "    code_layer.summary()\n",
    "    \n",
    "\n",
    "    \n",
    "    return auto_encoder, code_layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the autoencoder, and extract the code layer model for code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1000)              2049000   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2048)              2050048   \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DT (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DT (None, 32, 32, 3)         867       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 4,129,067\n",
      "Trainable params: 4,128,811\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1000)              2049000   \n",
      "=================================================================\n",
      "Total params: 2,059,400\n",
      "Trainable params: 2,059,272\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "180/180 [==============================] - 41s 228ms/step - loss: 0.0150 - acc: 0.7010 - val_loss: 0.0121 - val_acc: 0.7575\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 40s 224ms/step - loss: 0.0073 - acc: 0.7803 - val_loss: 0.0092 - val_acc: 0.7867\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 41s 229ms/step - loss: 0.0060 - acc: 0.8030 - val_loss: 0.0084 - val_acc: 0.8034\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 40s 223ms/step - loss: 0.0053 - acc: 0.8160 - val_loss: 0.0077 - val_acc: 0.8104\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 40s 223ms/step - loss: 0.0049 - acc: 0.8232 - val_loss: 0.0071 - val_acc: 0.8200\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 40s 224ms/step - loss: 0.0046 - acc: 0.8281 - val_loss: 0.0068 - val_acc: 0.8282\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 41s 226ms/step - loss: 0.0043 - acc: 0.8329 - val_loss: 0.0065 - val_acc: 0.8312\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 41s 229ms/step - loss: 0.0041 - acc: 0.8371 - val_loss: 0.0063 - val_acc: 0.8230\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 40s 224ms/step - loss: 0.0040 - acc: 0.8398 - val_loss: 0.0062 - val_acc: 0.8344\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 40s 223ms/step - loss: 0.0039 - acc: 0.8424 - val_loss: 0.0060 - val_acc: 0.8382\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 40s 221ms/step - loss: 0.0038 - acc: 0.8443 - val_loss: 0.0058 - val_acc: 0.8377\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 40s 222ms/step - loss: 0.0036 - acc: 0.8473 - val_loss: 0.0057 - val_acc: 0.8407: 0.0036 - acc:\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 39s 218ms/step - loss: 0.0036 - acc: 0.8478 - val_loss: 0.0056 - val_acc: 0.8411- ETA: 1s - loss: 0.0036 - acc: 0\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 40s 222ms/step - loss: 0.0035 - acc: 0.8493 - val_loss: 0.0054 - val_acc: 0.8375\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 40s 220ms/step - loss: 0.0034 - acc: 0.8523 - val_loss: 0.0054 - val_acc: 0.8456\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 40s 225ms/step - loss: 0.0033 - acc: 0.8531 - val_loss: 0.0053 - val_acc: 0.8459 2s - loss: 0.0033 - a\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 40s 222ms/step - loss: 0.0033 - acc: 0.8545 - val_loss: 0.0053 - val_acc: 0.8470\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 40s 221ms/step - loss: 0.0032 - acc: 0.8556 - val_loss: 0.0052 - val_acc: 0.8471\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 40s 222ms/step - loss: 0.0032 - acc: 0.8563 - val_loss: 0.0050 - val_acc: 0.8516\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 40s 222ms/step - loss: 0.0031 - acc: 0.8579 - val_loss: 0.0050 - val_acc: 0.8480\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 40s 222ms/step - loss: 0.0031 - acc: 0.8581 - val_loss: 0.0049 - val_acc: 0.8516\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 40s 222ms/step - loss: 0.0030 - acc: 0.8599 - val_loss: 0.0049 - val_acc: 0.8491\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 40s 221ms/step - loss: 0.0030 - acc: 0.8596 - val_loss: 0.0048 - val_acc: 0.8506\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 40s 222ms/step - loss: 0.0029 - acc: 0.8610 - val_loss: 0.0047 - val_acc: 0.85420029 - acc: 0.86 - ETA: 5s - lo\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 41s 227ms/step - loss: 0.0029 - acc: 0.8618 - val_loss: 0.0047 - val_acc: 0.8538\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 40s 223ms/step - loss: 0.0029 - acc: 0.8620 - val_loss: 0.0047 - val_acc: 0.8535\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 42s 233ms/step - loss: 0.0028 - acc: 0.8628 - val_loss: 0.0046 - val_acc: 0.8557\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 39s 216ms/step - loss: 0.0028 - acc: 0.8646 - val_loss: 0.0046 - val_acc: 0.8552\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 41s 229ms/step - loss: 0.0027 - acc: 0.8647 - val_loss: 0.0045 - val_acc: 0.8565\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 43s 241ms/step - loss: 0.0027 - acc: 0.8655 - val_loss: 0.0045 - val_acc: 0.8586\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 42s 233ms/step - loss: 0.0027 - acc: 0.8656 - val_loss: 0.0044 - val_acc: 0.8566\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 41s 226ms/step - loss: 0.0027 - acc: 0.8658 - val_loss: 0.0044 - val_acc: 0.8627\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 41s 226ms/step - loss: 0.0027 - acc: 0.8670 - val_loss: 0.0045 - val_acc: 0.8566\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 39s 219ms/step - loss: 0.0026 - acc: 0.8681 - val_loss: 0.0043 - val_acc: 0.8606oss: 0.0027 - acc: 0.86 - ETA - - ETA: 23s - loss: 0.0026 - acc: - ETA: 9s - loss: 0.0026 - - ETA: 7s  - ETA: 1s - loss: 0.0026 - acc: \n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 38s 214ms/step - loss: 0.0026 - acc: 0.8680 - val_loss: 0.0044 - val_acc: 0.8599026 -\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 39s 217ms/step - loss: 0.0026 - acc: 0.8673 - val_loss: 0.0043 - val_acc: 0.8608\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 40s 223ms/step - loss: 0.0026 - acc: 0.8693 - val_loss: 0.0043 - val_acc: 0.8589\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 41s 226ms/step - loss: 0.0026 - acc: 0.8693 - val_loss: 0.0042 - val_acc: 0.8617\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 39s 214ms/step - loss: 0.0025 - acc: 0.8698 - val_loss: 0.0042 - val_acc: 0.8628\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 40s 224ms/step - loss: 0.0025 - acc: 0.8708 - val_loss: 0.0041 - val_acc: 0.8640 1s - loss: 0.0025 - acc:\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 40s 223ms/step - loss: 0.0025 - acc: 0.8714 - val_loss: 0.0041 - val_acc: 0.8637 loss: 0.\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 41s 230ms/step - loss: 0.0025 - acc: 0.8715 - val_loss: 0.0042 - val_acc: 0.8588\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 40s 222ms/step - loss: 0.0024 - acc: 0.8726 - val_loss: 0.0041 - val_acc: 0.8656\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 40s 221ms/step - loss: 0.0024 - acc: 0.8720 - val_loss: 0.0040 - val_acc: 0.8643\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 39s 218ms/step - loss: 0.0024 - acc: 0.8738 - val_loss: 0.0041 - val_acc: 0.8613\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 40s 222ms/step - loss: 0.0024 - acc: 0.8733 - val_loss: 0.0040 - val_acc: 0.8653\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - 40s 220ms/step - loss: 0.0024 - acc: 0.8739 - val_loss: 0.0040 - val_acc: 0.8653\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - 40s 223ms/step - loss: 0.0024 - acc: 0.8736 - val_loss: 0.0040 - val_acc: 0.8585\n",
      "Epoch 49/50\n",
      "180/180 [==============================] - 40s 224ms/step - loss: 0.0024 - acc: 0.8744 - val_loss: 0.0040 - val_acc: 0.8655\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - 40s 220ms/step - loss: 0.0024 - acc: 0.8746 - val_loss: 0.0040 - val_acc: 0.8661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2313f6dc278>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,code_layer_model = auto_encoder()\n",
    "\n",
    "\n",
    "adam_optimizer = optimizers.Adam(lr=1e-3, decay=1e-6)\n",
    "model.compile(loss='mse',optimizer=adam_optimizer,metrics=['accuracy'])\n",
    "# set tensorboard\n",
    "NAME = \"Img_Clustering-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "#set modelcheckpoint\n",
    "\n",
    "MODELSAVENAME = \"model\\\\Img_Clustering_Best.h5\"\n",
    "checkpoint = ModelCheckpoint(DIR+\"{}\".format(MODELSAVENAME),monitor='val_acc', \\\n",
    "                                                      verbose=1, save_best_only=True, mode='max') # saves only the best ones\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = 36000 / BATCH_SIZE,\n",
    "        epochs = 50,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = 4000 / BATCH_SIZE,\n",
    "        callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "180/180 [==============================] - 41s 226ms/step - loss: 0.0023 - acc: 0.8749 - val_loss: 0.0040 - val_acc: 0.8664 0.0023 - acc: 0.874 - ETA: 2s - loss: 0.0023 - \n",
      "Epoch 2/20\n",
      "180/180 [==============================] - 41s 225ms/step - loss: 0.0023 - acc: 0.8751 - val_loss: 0.0040 - val_acc: 0.8588 - loss: 0.0023 - acc:  - ETA: 12s - lo - ETA: 0s - loss: 0.0023 - acc: 0.\n",
      "Epoch 3/20\n",
      "180/180 [==============================] - 39s 217ms/step - loss: 0.0023 - acc: 0.8758 - val_loss: 0.0040 - val_acc: 0.8671\n",
      "Epoch 4/20\n",
      "180/180 [==============================] - 39s 217ms/step - loss: 0.0023 - acc: 0.8763 - val_loss: 0.0038 - val_acc: 0.8680\n",
      "Epoch 5/20\n",
      "180/180 [==============================] - 39s 215ms/step - loss: 0.0023 - acc: 0.8767 - val_loss: 0.0039 - val_acc: 0.8677\n",
      "Epoch 6/20\n",
      "180/180 [==============================] - 39s 217ms/step - loss: 0.0023 - acc: 0.8766 - val_loss: 0.0040 - val_acc: 0.8633\n",
      "Epoch 7/20\n",
      "180/180 [==============================] - 39s 216ms/step - loss: 0.0023 - acc: 0.8764 - val_loss: 0.0039 - val_acc: 0.8636- \n",
      "Epoch 8/20\n",
      "180/180 [==============================] - 39s 216ms/step - loss: 0.0022 - acc: 0.8777 - val_loss: 0.0038 - val_acc: 0.8723A: \n",
      "Epoch 9/20\n",
      "180/180 [==============================] - 39s 216ms/step - loss: 0.0023 - acc: 0.8772 - val_loss: 0.0039 - val_acc: 0.8637\n",
      "Epoch 10/20\n",
      "180/180 [==============================] - 39s 216ms/step - loss: 0.0022 - acc: 0.8782 - val_loss: 0.0039 - val_acc: 0.8616.0022 - acc: - ETA: 3s - loss: 0.0022 - acc: - ETA: 2s - loss: 0.0022 - \n",
      "Epoch 11/20\n",
      "180/180 [==============================] - 39s 217ms/step - loss: 0.0022 - acc: 0.8784 - val_loss: 0.0038 - val_acc: 0.8651\n",
      "Epoch 12/20\n",
      "180/180 [==============================] - 39s 215ms/step - loss: 0.0022 - acc: 0.8784 - val_loss: 0.0038 - val_acc: 0.8632\n",
      "Epoch 13/20\n",
      "180/180 [==============================] - 39s 216ms/step - loss: 0.0022 - acc: 0.8789 - val_loss: 0.0038 - val_acc: 0.8654\n",
      "Epoch 14/20\n",
      "180/180 [==============================] - 39s 218ms/step - loss: 0.0022 - acc: 0.8788 - val_loss: 0.0038 - val_acc: 0.8675 - loss: 0.0022 - acc:\n",
      "Epoch 15/20\n",
      "180/180 [==============================] - 39s 217ms/step - loss: 0.0022 - acc: 0.8791 - val_loss: 0.0038 - val_acc: 0.8683\n",
      "Epoch 16/20\n",
      "180/180 [==============================] - 39s 216ms/step - loss: 0.0022 - acc: 0.8798 - val_loss: 0.0038 - val_acc: 0.8591\n",
      "Epoch 17/20\n",
      "180/180 [==============================] - 39s 216ms/step - loss: 0.0022 - acc: 0.8800 - val_loss: 0.0038 - val_acc: 0.8684s: 0.0022 - acc - ETA: 14s - lo - ETA: 11s - loss: 0.0022 - ETA: 10s - loss: 0.0022 - acc - ETA: 0s - loss: 0.0022 - acc: 0.\n",
      "Epoch 18/20\n",
      "180/180 [==============================] - 39s 216ms/step - loss: 0.0022 - acc: 0.8798 - val_loss: 0.0037 - val_acc: 0.8740\n",
      "Epoch 19/20\n",
      "180/180 [==============================] - 39s 217ms/step - loss: 0.0021 - acc: 0.8803 - val_loss: 0.0038 - val_acc: 0.8684\n",
      "Epoch 20/20\n",
      "180/180 [==============================] - 39s 216ms/step - loss: 0.0021 - acc: 0.8801 - val_loss: 0.0037 - val_acc: 0.8724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23140f7ce48>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = 36000 / BATCH_SIZE,\n",
    "        epochs = 20,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = 4000 / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the autoencoder\n",
    "AUTOENCODER_SAVE_NAME= \"model\\\\autoencoder.h5\"\n",
    "model.save(DIR+AUTOENCODER_SAVE_NAME)\n",
    "\n",
    "\n",
    "# Save the code_layer_model \n",
    "CODE_LAYER_SAVE_NAME= \"model\\\\code_layer_model.h5\"\n",
    "code_layer_model.save(DIR+CODE_LAYER_SAVE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## if above training codes are not run, run below optional block to load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model:\n",
    "AUTOENCODER_SAVE_NAME= \"model\\\\autoencoder.h5\"\n",
    "model = load_model(AUTOENCODER_SAVE_NAME)\n",
    "\n",
    "\n",
    "# code is (100,) shape\n",
    "CODE_LAYER_SAVE_NAME= \"model\\\\code_layer_model.h5\"\n",
    "code_layer_model = load_model(CODE_LAYER_SAVE_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build code dictionary array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "code_dictionary_array = code_layer_model.predict_generator(test_generator,steps = 40000/BATCH_SIZE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the code works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "%matplotlib inline\n",
    "\n",
    "test_generator.reset()\n",
    "generated_image = model.predict_generator(test_generator,steps = 40000/BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23140fd34a8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "io.imshow(generated_image[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use PCA to reduce the code vector, which will boost the discrimination. with PCA:0.96, without PCA: 0.6 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "reduced_dim = 500\n",
    "\n",
    "# set n_components= 0.99 if you want the number of dimensions(components) corresponds to 99% of the variance\n",
    "pca = PCA(n_components=reduced_dim, whiten=True , copy = False, svd_solver ='full')\n",
    "final_latent_code = pca.fit_transform(code_dictionary_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.08714245e-01, 6.86981678e-02, 4.97138314e-02, 4.27409522e-02,\n",
       "       3.33447158e-02, 3.05652246e-02, 2.98274793e-02, 2.63231564e-02,\n",
       "       2.31066030e-02, 2.02045254e-02, 1.51523966e-02, 1.39007010e-02,\n",
       "       1.29959527e-02, 1.18492283e-02, 1.13601871e-02, 1.04989475e-02,\n",
       "       9.97801125e-03, 9.47961584e-03, 8.90864246e-03, 8.33202805e-03,\n",
       "       8.11758172e-03, 7.92022422e-03, 7.64848385e-03, 7.14610144e-03,\n",
       "       7.11172586e-03, 6.96396362e-03, 6.61390787e-03, 6.34532934e-03,\n",
       "       6.24405360e-03, 5.97041147e-03, 5.75119397e-03, 5.43601532e-03,\n",
       "       5.28219203e-03, 5.16289379e-03, 5.07031288e-03, 5.01732482e-03,\n",
       "       4.73434851e-03, 4.55436017e-03, 4.48884116e-03, 4.39408794e-03,\n",
       "       4.29226272e-03, 4.22861194e-03, 4.16514510e-03, 4.05204948e-03,\n",
       "       3.89520708e-03, 3.86338122e-03, 3.81527632e-03, 3.71637102e-03,\n",
       "       3.62637779e-03, 3.52946250e-03, 3.42688570e-03, 3.39652970e-03,\n",
       "       3.32516502e-03, 3.23008024e-03, 3.16350465e-03, 3.11915786e-03,\n",
       "       3.08901654e-03, 3.04729422e-03, 2.96095666e-03, 2.92366021e-03,\n",
       "       2.88982666e-03, 2.86155310e-03, 2.82726949e-03, 2.77242134e-03,\n",
       "       2.75032362e-03, 2.67838780e-03, 2.63353530e-03, 2.62232148e-03,\n",
       "       2.57697166e-03, 2.49438407e-03, 2.47755577e-03, 2.45875190e-03,\n",
       "       2.45200121e-03, 2.41109077e-03, 2.36292556e-03, 2.34277220e-03,\n",
       "       2.30050110e-03, 2.25352310e-03, 2.23246962e-03, 2.18391675e-03,\n",
       "       2.17596884e-03, 2.14985013e-03, 2.11911951e-03, 2.07398064e-03,\n",
       "       2.07206258e-03, 2.05209898e-03, 2.02137558e-03, 1.99304288e-03,\n",
       "       1.96625292e-03, 1.92961015e-03, 1.91577256e-03, 1.89959398e-03,\n",
       "       1.88876095e-03, 1.87552092e-03, 1.84323906e-03, 1.83244480e-03,\n",
       "       1.80560525e-03, 1.79755152e-03, 1.76770589e-03, 1.74309628e-03,\n",
       "       1.72888103e-03, 1.71451061e-03, 1.68032746e-03, 1.67184323e-03,\n",
       "       1.64884224e-03, 1.62795908e-03, 1.61206082e-03, 1.57850236e-03,\n",
       "       1.57118647e-03, 1.56274543e-03, 1.53262890e-03, 1.52787752e-03,\n",
       "       1.51653099e-03, 1.50828867e-03, 1.50048209e-03, 1.49790524e-03,\n",
       "       1.47454499e-03, 1.46287109e-03, 1.44553499e-03, 1.43454864e-03,\n",
       "       1.42677734e-03, 1.41889811e-03, 1.38144603e-03, 1.37332431e-03,\n",
       "       1.36250851e-03, 1.34114479e-03, 1.33856595e-03, 1.32884399e-03,\n",
       "       1.32176734e-03, 1.29254407e-03, 1.28598348e-03, 1.28414447e-03,\n",
       "       1.27246603e-03, 1.24567677e-03, 1.24313158e-03, 1.22367486e-03,\n",
       "       1.21362018e-03, 1.20091101e-03, 1.19626895e-03, 1.18270272e-03,\n",
       "       1.17513363e-03, 1.15958892e-03, 1.14691944e-03, 1.12967344e-03,\n",
       "       1.11563609e-03, 1.09960348e-03, 1.09285128e-03, 1.08216552e-03,\n",
       "       1.07670110e-03, 1.06064661e-03, 1.05598057e-03, 1.04437582e-03,\n",
       "       1.03908649e-03, 1.02614705e-03, 1.01518712e-03, 1.00020855e-03,\n",
       "       9.96038434e-04, 9.83806443e-04, 9.74151189e-04, 9.60129080e-04,\n",
       "       9.48221015e-04, 9.39668738e-04, 9.35318356e-04, 9.25191329e-04,\n",
       "       9.09010880e-04, 9.03103501e-04, 8.90672498e-04, 8.83763889e-04,\n",
       "       8.78527819e-04, 8.70175310e-04, 8.66555667e-04, 8.52636294e-04,\n",
       "       8.46451090e-04, 8.43168469e-04, 8.33058788e-04, 8.22773261e-04,\n",
       "       8.09989520e-04, 8.05474352e-04, 7.99907953e-04, 7.92343402e-04,\n",
       "       7.81831623e-04, 7.74681976e-04, 7.72461470e-04, 7.70368439e-04,\n",
       "       7.49654602e-04, 7.45716447e-04, 7.37358001e-04, 7.35956477e-04,\n",
       "       7.24353129e-04, 7.18231953e-04, 7.15004746e-04, 7.13380461e-04,\n",
       "       7.03612983e-04, 6.98703399e-04, 6.84813305e-04, 6.81005069e-04,\n",
       "       6.74265611e-04, 6.73499249e-04, 6.56401273e-04, 6.54255622e-04,\n",
       "       6.45514228e-04, 6.41116058e-04, 6.32559706e-04, 6.25065237e-04,\n",
       "       6.17268786e-04, 6.16932986e-04, 6.12620148e-04, 6.01515232e-04,\n",
       "       5.98078361e-04, 5.92195545e-04, 5.87850402e-04, 5.83491114e-04,\n",
       "       5.74630511e-04, 5.68233663e-04, 5.59127948e-04, 5.50642610e-04,\n",
       "       5.44312119e-04, 5.40605455e-04, 5.35794010e-04, 5.28971374e-04,\n",
       "       5.26564429e-04, 5.21816895e-04, 5.12339291e-04, 5.04940865e-04,\n",
       "       5.02531067e-04, 4.99748276e-04, 4.92198451e-04, 4.83694661e-04,\n",
       "       4.81007854e-04, 4.73783613e-04, 4.70910978e-04, 4.67877049e-04,\n",
       "       4.57688206e-04, 4.57005081e-04, 4.51229222e-04, 4.48605831e-04,\n",
       "       4.43450146e-04, 4.36840404e-04, 4.34233923e-04, 4.31189022e-04,\n",
       "       4.27236955e-04, 4.21298173e-04, 4.15086164e-04, 4.08528227e-04,\n",
       "       4.06834501e-04, 3.95409006e-04, 3.92799644e-04, 3.92083166e-04,\n",
       "       3.86540167e-04, 3.80223035e-04, 3.74819443e-04, 3.74401949e-04,\n",
       "       3.68124223e-04, 3.64981708e-04, 3.63426574e-04, 3.60450911e-04,\n",
       "       3.52022849e-04, 3.49570561e-04, 3.41578270e-04, 3.35721823e-04,\n",
       "       3.34141019e-04, 3.28841823e-04, 3.25757428e-04, 3.22155363e-04,\n",
       "       3.18387873e-04, 3.12488788e-04, 3.08767485e-04, 3.00650747e-04,\n",
       "       2.96689046e-04, 2.90061696e-04, 2.88401759e-04, 2.85751419e-04,\n",
       "       2.82065157e-04, 2.74507795e-04, 2.71667464e-04, 2.71231809e-04,\n",
       "       2.68632779e-04, 2.65912880e-04, 2.61939189e-04, 2.60011846e-04,\n",
       "       2.57272535e-04, 2.53649079e-04, 2.50177603e-04, 2.45902105e-04,\n",
       "       2.43541042e-04, 2.39908244e-04, 2.38064764e-04, 2.33632818e-04,\n",
       "       2.32245991e-04, 2.26433142e-04, 2.24326752e-04, 2.18852671e-04,\n",
       "       2.15633569e-04, 2.13795152e-04, 2.07639387e-04, 2.06575831e-04,\n",
       "       2.03473814e-04, 2.01753151e-04, 1.99735252e-04, 1.96683963e-04,\n",
       "       1.94301872e-04, 1.91314379e-04, 1.89713319e-04, 1.87351354e-04,\n",
       "       1.86220394e-04, 1.83280368e-04, 1.79987983e-04, 1.76527552e-04,\n",
       "       1.75332389e-04, 1.74092595e-04, 1.67918857e-04, 1.65469755e-04,\n",
       "       1.64136130e-04, 1.61371587e-04, 1.60086987e-04, 1.58031282e-04,\n",
       "       1.57432078e-04, 1.55297108e-04, 1.52231878e-04, 1.48605177e-04,\n",
       "       1.44741920e-04, 1.44006757e-04, 1.41961282e-04, 1.39908385e-04,\n",
       "       1.39284777e-04, 1.37838884e-04, 1.34487433e-04, 1.33327907e-04,\n",
       "       1.31977751e-04, 1.28453510e-04, 1.25839157e-04, 1.25313556e-04,\n",
       "       1.24964528e-04, 1.23537277e-04, 1.21559860e-04, 1.19573888e-04,\n",
       "       1.18898453e-04, 1.16182287e-04, 1.14971532e-04, 1.13594513e-04,\n",
       "       1.12657450e-04, 1.11540743e-04, 1.10185007e-04, 1.08196044e-04,\n",
       "       1.07372478e-04, 1.06445725e-04, 1.03822305e-04, 1.03376435e-04,\n",
       "       1.02677157e-04, 1.01284699e-04, 9.93576614e-05, 9.86575251e-05,\n",
       "       9.79078759e-05, 9.68841923e-05, 9.59202080e-05, 9.51675102e-05,\n",
       "       9.46432265e-05, 9.32985058e-05, 9.19277372e-05, 9.14098200e-05,\n",
       "       9.11212410e-05, 9.00314990e-05, 8.84787514e-05, 8.82486493e-05,\n",
       "       8.75291880e-05, 8.66072223e-05, 8.60064247e-05, 8.52562225e-05,\n",
       "       8.41167566e-05, 8.37367188e-05, 8.31690340e-05, 8.24416129e-05,\n",
       "       8.17301479e-05, 8.08757977e-05, 8.05974414e-05, 8.01522910e-05,\n",
       "       7.92870196e-05, 7.85083830e-05, 7.83620271e-05, 7.79063412e-05,\n",
       "       7.71561681e-05, 7.61429037e-05, 7.60377661e-05, 7.54791035e-05,\n",
       "       7.49746250e-05, 7.45626749e-05, 7.40824325e-05, 7.30332686e-05,\n",
       "       7.26967701e-05, 7.21854667e-05, 7.13128611e-05, 7.07131330e-05,\n",
       "       7.05789789e-05, 7.03501864e-05, 7.00666060e-05, 6.92471949e-05,\n",
       "       6.87102511e-05, 6.81919992e-05, 6.81240126e-05, 6.79067743e-05,\n",
       "       6.66987908e-05, 6.64376857e-05, 6.56509364e-05, 6.54809046e-05,\n",
       "       6.51249720e-05, 6.49697395e-05, 6.43770181e-05, 6.37830308e-05,\n",
       "       6.34922108e-05, 6.33329328e-05, 6.27443442e-05, 6.19830753e-05,\n",
       "       6.15088065e-05, 6.12935255e-05, 6.10202769e-05, 6.06239519e-05,\n",
       "       6.04247580e-05, 6.00020212e-05, 5.96513964e-05, 5.90302006e-05,\n",
       "       5.88402472e-05, 5.86001006e-05, 5.83266628e-05, 5.77838982e-05,\n",
       "       5.75819140e-05, 5.73850339e-05, 5.70664124e-05, 5.66720628e-05,\n",
       "       5.65014852e-05, 5.58487700e-05, 5.54075559e-05, 5.52649362e-05,\n",
       "       5.50302066e-05, 5.46449191e-05, 5.44585455e-05, 5.41157679e-05,\n",
       "       5.35946492e-05, 5.32529957e-05, 5.31070764e-05, 5.27667617e-05,\n",
       "       5.25123069e-05, 5.20646172e-05, 5.19445493e-05, 5.15923239e-05,\n",
       "       5.13652085e-05, 5.10673126e-05, 5.08731791e-05, 5.06737633e-05,\n",
       "       5.05234602e-05, 5.03182455e-05, 4.99393245e-05, 4.96297034e-05,\n",
       "       4.92587060e-05, 4.89073354e-05, 4.88547885e-05, 4.86039571e-05,\n",
       "       4.85042838e-05, 4.83770928e-05, 4.79462797e-05, 4.77484391e-05,\n",
       "       4.74502958e-05, 4.72493339e-05, 4.69708320e-05, 4.67789141e-05,\n",
       "       4.65997764e-05, 4.64092409e-05, 4.62391981e-05, 4.59835828e-05,\n",
       "       4.56585221e-05, 4.55462869e-05, 4.53575740e-05, 4.52288950e-05,\n",
       "       4.50809821e-05, 4.49044710e-05, 4.46512422e-05, 4.44490797e-05,\n",
       "       4.42017990e-05, 4.40268632e-05, 4.37164199e-05, 4.35024886e-05,\n",
       "       4.34663962e-05, 4.31186854e-05, 4.30796899e-05, 4.27198465e-05,\n",
       "       4.24622376e-05, 4.23764541e-05, 4.23093661e-05, 4.20094439e-05,\n",
       "       4.18220443e-05, 4.15707509e-05, 4.14677124e-05, 4.11095316e-05,\n",
       "       4.10516986e-05, 4.10124048e-05, 4.05991923e-05, 4.05654027e-05,\n",
       "       4.02364531e-05, 4.00325516e-05, 3.98046213e-05, 3.96667965e-05],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try t-SNE. t-SNE is normally used for visualization. so try to set n_components = 2 to visualize the transformed latent codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# tsne = TSNE(n_components=2,random_state=0)\n",
    "# final_latent_code_visualize = tsne.fit_transform(code_dictionary_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build discrimination function using K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(final_latent_code)\n",
    "\n",
    "def discriminate(img1_num,img2_num):\n",
    "    \n",
    "    #if two pics are in the same cluster, with same label, then return 1, otherwise return 0\n",
    "    if kmeans.labels_[img1_num - 1] == kmeans.labels_[img2_num - 1]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load testcase.csv and output Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26433, 24161], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "testcase = pd.read_csv(DIR + \"test_case.csv\")\n",
    "feature_names = [\"image1_name\",\"image2_name\"]\n",
    "testcase_image_pair = testcase[feature_names].values\n",
    "testcase_image_pair[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [discriminate(testcase_image_pair[i][0],testcase_image_pair[i][1]) for i in range(testcase_image_pair.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(DIR+'sample_submission.csv')\n",
    "sample_submission ['label'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission_wu.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
